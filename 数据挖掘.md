# 数据挖掘

## 分箱问题

### 分箱

- 等深
- 等宽

### 数据变化（标准化）

- 最小-最大规范化
\[ x' = \frac{x - \text{min}}{\text{max} - \text{min}} \]

- z-scors规范化
\[ x' = \frac{x - \text{mean}}{\text{std}} \]

- 小数定标规范化
\[ x' = \frac{x}{10^j} \]

## 神经网络

### 单BP神经网络

给定x1，x2，x3，w1i,w2j,θj，计算y值…………

### 激活函数

- 阈值型函数
 \[ y = \begin{cases} 1, & \text{if } x > 0 \\ 0, & \text{if } x \leq 0 \end{cases} \]

- 分段线性函数
\[ y = \begin{cases} 1, & \text{if } x > X_i \\ x, & \text{if } X_i \geq x > 0 \\ 0, & \text{if } x \leq 0 \end{cases} \]

- Sigmoid函数
\[ y = \frac{1}{1 + e^{-\lambda x}} \]

- 高斯函数
\[ y = e^{-(x^2 / (2 \sigma^2))} \]

## 贝叶斯公式

### 概率

先验概率：在考虑任何新观测或证据之前，对事件的概率的初始估计
后验概率：在考虑新的证据或信息之后，对事件概率的更新估计
主观概率：基于个体主观判断和信念而非统计数据的概率

### 贝叶斯分类器

朴素贝叶斯分类器：假设特征之间相互独立，即每个特征都是独立的，不依赖于其他特征
方法：计算每个类别的先验概率和每个特征的条件概率，然后将它们相乘，得到每个类别的后验概率，最后选择具有最大后验概率的类别作为预测结果
110页 例5.2（步骤重点）

## 关联规则（apriori算法）

apriori规则：如果某个项集是频繁的，那么它的所有子集也是频繁的,如果某个项集是非频繁的，那么它的所有超集也是非频繁的

apriori算法：先找出所有的频繁项集，然后由频繁项集产生关联规则

1. 生成候选项集

   - 扫描数据集，统计每个项的支持度。
   - 根据最小支持度阈值，过滤掉低于阈值的项，得到频繁1-项集。

2. 迭代生成频繁项集

   - 基于频繁k-1项集，通过连接操作生成候选k项集。
   - 再次扫描数据集，统计每个候选项集的支持度。
   - 过滤掉低于最小支持度阈值的候选项集，得到频繁k项集。

3. 提取关联规则

   - 根据频繁项集，生成关联规则。
   - 对于每个频繁项集，考虑所有可能的非空子集，生成关联规则。
   - 计算规则的置信度，并筛选出满足最小置信度阈值的规则。

4. 重复迭代直到不再生成频繁项集

   - 重复步骤2和步骤3，直到不能再生成更多的频繁项集。

注意：**禁止暴力枚举**

## 决策树

决策树分类算法的树的结构:一种树形结构，其中每个内部节点表示一个属性上的测试，每个分支代表一个测试输出，每个叶节点代表一种类别。决策树的学习过程就是从训练数据中归纳出一组分类规则。

信息增益的计算方法

1. **计算数据集的熵（Entropy）：**
   - 对于分类问题，熵是度量数据集纯度的指标。
   - 数据集的熵越高，说明数据集的混合程度越大，纯度越低。
   - 熵的计算公式为：\[ \text{Entropy}(S) = -p_1 \log_2(p_1) - p_2 \log_2(p_2) - \ldots - p_k \log_2(p_k) \]
     其中，\( p_i \) 是数据集中属于类别 \( i \) 的样本占总样本数的比例。

2. **计算特征的条件熵（Conditional Entropy）：**
   - 条件熵是在已知某个特征的情况下，数据集的熵。
   - 对于特征 \( A \)，其条件熵的计算公式为：\[ \text{H}(S|A) = \sum_{i=1}^{n} \frac{|S_i|}{|S|} \cdot \text{Entropy}(S_i) \]
     其中，\( n \) 是特征 \( A \) 的取值个数，\( S_i \) 是在特征 \( A \) 下取值为 \( i \) 的子集。

3. **计算信息增益（Information Gain）：**
   - 信息增益是熵和条件熵之差，表示特征 \( A \) 对分类任务的贡献程度。
   - 信息增益的计算公式为：\[ \text{Information Gain}(S, A) = \text{Entropy}(S) - \text{H}(S|A) \]

在决策树算法中，选择具有最大信息增益的特征作为当前节点的划分特征。这个过程递归地进行，直到满足停止条件，形成决策树模型。

## K均值聚类

K均值聚类算法：给定样本集，将样本集划分为K个簇，使得每个样本点都属于离它最近的均值点所在的簇，以均值点为中心，簇内样本点到均值点的距离之和最小。

## 大题

- 贝叶斯
- 关联规则（apriori）
- 决策树
- K均值聚类
